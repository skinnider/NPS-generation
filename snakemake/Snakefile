configfile: "config.json"
threads: 1
# -----------------------------------------------------------------------------
# Setup
# -----------------------------------------------------------------------------
DATASET = os.path.splitext(os.path.basename(config["dataset"]))[0]
REPRESENTATIONS = config["representations"]
SEEDS = config["seeds"]
FOLDS = config["folds"]
ENUM_FACTORS = config["enum_factors"]
METRICS = config["metrics"]
OUTPUT_DIR = config['output_dir']
MODEL_PARAMS = config['model_params']
ERR_PPM = config['err_ppm']

shell.executable("/bin/bash")

wildcard_constraints:
    dataset=DATASET,
    repr='|'.join(REPRESENTATIONS),
    fold='\d+',
    seed='\d+'

# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Rules
# -----------------------------------------------------------------------------
rule all:
    input:
        output_file=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_processed_{{metric}}.csv", enum_factor=ENUM_FACTORS, dataset=DATASET, repr=REPRESENTATIONS, metric=METRICS),
        ranks_file_formula=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_ranks_formula.csv.gz",
                       enum_factor=ENUM_FACTORS, dataset=DATASET, repr=REPRESENTATIONS, seed=SEEDS, fold=range(FOLDS)),
        ranks_file_structure=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_ranks_structure.csv.gz",
                   enum_factor=ENUM_FACTORS, dataset=DATASET, repr=REPRESENTATIONS, seed=SEEDS, fold=range(FOLDS)),
        tc_file=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_tc.csv.gz",
                   enum_factor=ENUM_FACTORS, dataset=DATASET, repr=REPRESENTATIONS, seed=SEEDS, fold=range(FOLDS))

rule preprocess:
    """
    Read input smiles and save a file of "canonical" smiles. This entails:
    Conversion to molecules using rdkit, removing light fragments,
    neutralizing charges, filtering for valid elements
    removing rare tokens in the smiles vocabulary.
    """
    input:
        f"{config['dataset']}"
    output:
        f"{OUTPUT_DIR}/prior/raw/{{dataset}}.txt"
    resources:
        mem_mb=12000,
        runtime=30,
    shell:
        'nps preprocess '
        '--input-file {input} '
        '--output-file {output} '
        '--max-input-smiles {config[max_input_smiles]} '


rule create_training_sets:
    """
    Split input smiles into separate files for train/test folds,
    while also creating a .vocabulary files for the training smiles.
    Optionally takes in a min_tc parameter to only consider smiles that
    are similar to a randomly selected seed smile.
    """
    input:
        f"{OUTPUT_DIR}/prior/raw/{{dataset}}.txt"
    output:
        train_file = f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi",
        vocab_file = f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.vocabulary",
        test_file = f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/test_{{dataset}}_{{repr}}_{{fold}}.smi"
    resources:
        mem_mb=20000,
        runtime=10,
    shell:
        'nps create_training_sets '
        '--input-file {input} '
        '--train-file {output.train_file} '
        '--vocab-file {output.vocab_file} '
        '--test-file {output.test_file} '
        '--enum-factor {wildcards.enum_factor} '
        '--folds {FOLDS} '
        '--representation {wildcards.repr} '
        '--min-tc 0 '
        '--max-input-smiles {config[max_input_smiles]} '


rule train_models_RNN:
    """
    Train |seed| RNN models on an input fold.
    Each training fold is internally split into train/validation split of 0.9.
    Write out the model file and loss file. Optionally sample a small set of
    smiles and write them out to `smiles_file`.
    """
    input:
        input_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi",
        vocab_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.vocabulary"
    output:
        model_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/models/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_model.pt",
        loss_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/models/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_loss.csv"
    resources:
        mem_mb=32000,
        runtime=MODEL_PARAMS["max_epochs"]*120,
        slurm_extra="--gres=gpu:1"
    shell:
            'python ../python/inner-train-models-RNN.py '
            '--database {wildcards.dataset} '
            '--representation {wildcards.repr} '
            '--min_tc {MODEL_PARAMS[min_tc]} '
            '--seed {wildcards.seed} '
            '--rnn_type {MODEL_PARAMS[rnn_type]} '
            '--embedding_size {MODEL_PARAMS[embedding_size]} '
            '--hidden_size {MODEL_PARAMS[hidden_size]} '
            '--n_layers {MODEL_PARAMS[n_layers]} '
            '--dropout {MODEL_PARAMS[dropout]} '
            '--batch_size {MODEL_PARAMS[batch_size]} '
            '--learning_rate {MODEL_PARAMS[learning_rate]} '
            '--max_epochs {MODEL_PARAMS[max_epochs]} '
            '--patience {MODEL_PARAMS[patience]} '
            '--log_every_steps {MODEL_PARAMS[log_every_steps]} '
            '--log_every_epochs {MODEL_PARAMS[log_every_epochs]} '
            '--sample_mols {MODEL_PARAMS[sample_mols]} '
            '--input_file {input.input_file} '
            '--vocab_file {input.vocab_file} '
            '--model_file {output.model_file} '
            '--loss_file {output.loss_file} '


rule sample_molecules_RNN:
    """
    Sample `sample_mols` smiles from a trained model and fole, and save to
    `output_file`. Each line of `output_file` is (<mass>, <smile>).
    """
    input:
        vocab_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.vocabulary",
        model_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/models/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_model.pt"
    output:
        output_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_samples.csv"
    resources:
        mem_mb=1000,
        runtime=MODEL_PARAMS["sample_mols"]//10000,
        slurm_extra="--gres=gpu:1"
    shell:
        'python ../python/inner-sample-molecules-RNN.py '
        '--database {wildcards.dataset} '
        '--representation {wildcards.repr} '
        '--min_tc {MODEL_PARAMS[min_tc]} '
        '--rnn_type {MODEL_PARAMS[rnn_type]} '
        '--embedding_size {MODEL_PARAMS[embedding_size]} '
        '--hidden_size {MODEL_PARAMS[hidden_size]} '
        '--n_layers {MODEL_PARAMS[n_layers]} '
        '--dropout {MODEL_PARAMS[dropout]} '
        '--batch_size {MODEL_PARAMS[batch_size]} '
        '--learning_rate {MODEL_PARAMS[learning_rate]} '
        '--sample_mols {MODEL_PARAMS[sample_mols]} '
        '--vocab_file {input.vocab_file} '
        '--model_file {input.model_file} '
        '--output_file {output.output_file} '


rule tabulate_molecules:
    """
    For sampled smiles from a model and a fold, add mass, formula and sampling
    frequency. Filter out smiles that are found in `train_file`.
    """
    input:
        input_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_samples.csv",
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi",
    output:
        output_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_samples_masses.csv",
    resources:
        mem_mb=4000,
        runtime=MODEL_PARAMS["sample_mols"]//1000,
    shell:
        'python ../python/inner-tabulate-molecules.py '
        '--input_file {input.input_file} '
        '--train_file {input.train_file} '
        '--representation {wildcards.repr} '
        '--output_file {output.output_file} '


rule collect_tabulated_molecules:
    """
    Aggregate sampled smiles from all models run on a fold, adding
    sampling frequency in the process.
    """
    input:
        input_files=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_{{seed}}_samples_masses.csv", seed=SEEDS, allow_missing=True)
    output:
        output_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv",
    resources:
        mem_mb=4000,
        runtime=MODEL_PARAMS["sample_mols"]//1000,
    shell:
        'python ../python/inner-collect-tabulated-molecules.py '
        '--input_files {input.input_files} '
        '--output_file {output.output_file} '


rule process_tabulated_molecules:
    """
    Aggregate sampled smiles across all folds, calculating metrics like
    average sampling frequency (if metric=freq-avg), freq-sum etc.
    Smiles found in training data (i.e. in `cv_file`) are not counted towards
    the aggregated metric.
    """
    input:
        input_file=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{DATASET}_{{repr}}_{{fold}}_unique_masses.csv", fold=range(FOLDS), allow_missing=True),
        cv_file=expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi", fold=range(FOLDS), allow_missing=True)
    output:
        output_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_processed_{{metric}}.csv",
    resources:
        mem_mb=4000,
        runtime=MODEL_PARAMS["sample_mols"]//1000,
    shell:
        'python ../python/inner-process-tabulated-molecules.py '
        '--input_file {input.input_file} '
        '--cv_file {input.cv_file} '
        '--output_file {output.output_file} '
        '--summary_fn {wildcards.metric} '


rule write_structural_prior_CV:
    """
    Evaluate test smiles against the trained models, with PubChem as a baseline.
    
    For each fold, for each smile in the test dataset, generate statistics for
    the occurrence of the test smile in each of the 3 "models":
      <trained_smiles>/<sampled_smiles>/PubChem.
    
    For each of the 3 "models", keep track of smiles that fall within some
    tolerance of the true test-smile molecular weight. When sorted by decreasing
    sampling frequency, the rank at which we find the "correct" smile
    (in terms of a match in the smile string), gives us the
    "rank" of each test smile. Lower ranks indicate a better model.
    
    This output is written to `ranks_file`.
    
    Fingerprint similarity values are written out to `tc_file`.
    """
    input:
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi",
        test_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/test_{{dataset}}_{{repr}}_{{fold}}.smi",
        pubchem_file=config['pubchem_tsv_file'],
        sample_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv"
    output:
         ranks_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_ranks_structure.csv.gz",
         tc_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_tc.csv.gz"
    resources:
        mem_mb=32000,
        runtime=180,
    shell:
        'python ../python/inner-write-structural-prior-CV.py '
        '--ranks_file {output.ranks_file} '
        '--tc_file {output.tc_file} '
        '--train_file {input.train_file} '
        '--test_file {input.test_file} '
        '--pubchem_file {input.pubchem_file} '
        '--sample_file {input.sample_file} '
        '--err_ppm {ERR_PPM} '


rule write_formula_prior_CV:
    """
    NOTE: Analogous to `write_structural_prior_CV`, but "correctness" is based
    on a matching formula, not a matching smile. Read on for full details.
    
    Evaluate test smiles against the trained models, with PubChem as a baseline.

    For each fold, for each smile in the test dataset, generate statistics for
    the occurrence of the test smile in each of the 3 "models":
      <trained_smiles>/<sampled_smiles>/PubChem.

    For each of the 3 "models", keep track of smiles that fall within some
    tolerance of the true test-smile molecular weight. When sorted by decreasing
    sampling frequency, the rank at which we find the "correct" smile
    (in terms of the correct formula), gives us the
    "rank" of each test smile. Lower ranks indicate a better model.
    
    This output is written to `ranks_file`.
    """
    input:
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train_{{dataset}}_{{repr}}_{{fold}}.smi",
        test_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/test_{{dataset}}_{{repr}}_{{fold}}.smi",
        pubchem_file=config['pubchem_tsv_file'],
        sample_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv"
    output:
         ranks_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_{{fold}}_CV_ranks_formula.csv.gz"
    resources:
        mem_mb=32000,
        runtime=180,
    shell:
        'python ../python/inner-write-formula-prior-CV.py '
        '--ranks_file {output.ranks_file} '
        '--train_file {input.train_file} '
        '--test_file {input.test_file} '
        '--pubchem_file {input.pubchem_file} '
        '--sample_file {input.sample_file} '
        '--err_ppm {ERR_PPM} '
